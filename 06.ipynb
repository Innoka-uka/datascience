{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 数据获取：数据集已下载至`bike.csv`文件中，请使用pandas库读取该文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id  city  hour  is_workday  weather  temp_1  temp_2  wind    y\n",
      "0         1     0    22           1        2     3.0     0.7     0   15\n",
      "1         2     0    10           1        1    21.0    24.9     3   48\n",
      "2         3     0     0           1        1    25.3    27.4     0   21\n",
      "3         4     0     7           0        1    15.7    16.2     0   11\n",
      "4         5     1    10           1        1    21.1    25.0     2   39\n",
      "...     ...   ...   ...         ...      ...     ...     ...   ...  ...\n",
      "9995   9996     0     4           0        2     8.3     7.3     0    2\n",
      "9996   9997     1     5           0        1    22.3    22.2     0    1\n",
      "9997   9998     1     0           0        1     9.6     9.7     0   11\n",
      "9998   9999     0    18           0        2    27.4    29.7     1  105\n",
      "9999  10000     0     9           1        2     3.2    -2.1     2   48\n",
      "\n",
      "[10000 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取 CSV 文件\n",
    "df = pd.read_csv('data/bike.csv')\n",
    "\n",
    "# 打印 DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " 2. 数据预处理 I：`id`属性对构建回归预测模型没有帮助，请剔除掉该列。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "删除 'id' 列后的 DataFrame:\n",
      "      city  hour  is_workday  weather  temp_1  temp_2  wind    y\n",
      "0        0    22           1        2     3.0     0.7     0   15\n",
      "1        0    10           1        1    21.0    24.9     3   48\n",
      "2        0     0           1        1    25.3    27.4     0   21\n",
      "3        0     7           0        1    15.7    16.2     0   11\n",
      "4        1    10           1        1    21.1    25.0     2   39\n",
      "...    ...   ...         ...      ...     ...     ...   ...  ...\n",
      "9995     0     4           0        2     8.3     7.3     0    2\n",
      "9996     1     5           0        1    22.3    22.2     0    1\n",
      "9997     1     0           0        1     9.6     9.7     0   11\n",
      "9998     0    18           0        2    27.4    29.7     1  105\n",
      "9999     0     9           1        2     3.2    -2.1     2   48\n",
      "\n",
      "[10000 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "# 删除指定列\n",
    "df = df.drop(columns=['id'])\n",
    "\n",
    "# 打印删除列后的 DataFrame\n",
    "print(\"\\n删除 'id' 列后的 DataFrame:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. 数据预处理 II：我们暂不考虑不同城市对单车租用的影响，请筛选出上海市的所有数据，然后剔除`city`列。\n",
    "\n",
    "> 提示：目前剩余4,998条数据。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      hour  is_workday  weather  temp_1  temp_2  wind    y\n",
      "4       10           1        1    21.1    25.0     2   39\n",
      "5        0           1        1    20.4    18.2     0   12\n",
      "9        4           1        3    17.4    18.0     3    2\n",
      "10       0           1        1    14.9    15.3     2    6\n",
      "11       8           0        1    25.0    28.1     0   25\n",
      "...    ...         ...      ...     ...     ...   ...  ...\n",
      "9990    23           1        2    19.2    19.9     1   44\n",
      "9991    19           1        1    25.1    26.2     2  124\n",
      "9993     5           1        3    13.7    14.1     2    1\n",
      "9996     5           0        1    22.3    22.2     0    1\n",
      "9997     0           0        1     9.6     9.7     0   11\n",
      "\n",
      "[4998 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "sh = df[df['city']==1]\n",
    "sh = sh.drop(columns=['city'])\n",
    "print(sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. 数据预处理 III：为简化数据，请将`hour`列中原来6点-18点统一为1；19点-次日5点统一为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      hour  is_workday  weather  temp_1  temp_2  wind    y\n",
      "4        1           1        1    21.1    25.0     2   39\n",
      "5        0           1        1    20.4    18.2     0   12\n",
      "9        0           1        3    17.4    18.0     3    2\n",
      "10       0           1        1    14.9    15.3     2    6\n",
      "11       1           0        1    25.0    28.1     0   25\n",
      "...    ...         ...      ...     ...     ...   ...  ...\n",
      "9990     0           1        2    19.2    19.9     1   44\n",
      "9991     0           1        1    25.1    26.2     2  124\n",
      "9993     0           1        3    13.7    14.1     2    1\n",
      "9996     0           0        1    22.3    22.2     0    1\n",
      "9997     0           0        1     9.6     9.7     0   11\n",
      "\n",
      "[4998 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "sh.loc[:, 'hour'] = np.where((sh['hour'] >= 6) & (sh['hour'] <= 18), 1, 0)\n",
    "print(sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. 数据预处理 IV：`y`列为单车租用数量，是我们的预测目标（标签），请将该列提取出来，并转换为一个numpy**列向量**，将原先的`y`列剔除。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y 列的 NumPy 列向量: \n",
      "\n",
      "[[39]\n",
      " [12]\n",
      " [ 2]\n",
      " ...\n",
      " [ 1]\n",
      " [ 1]\n",
      " [11]]\n",
      "\n",
      "删除 'y' 列后的 数据:\n",
      "      hour  is_workday  weather  temp_1  temp_2  wind\n",
      "4        1           1        1    21.1    25.0     2\n",
      "5        0           1        1    20.4    18.2     0\n",
      "9        0           1        3    17.4    18.0     3\n",
      "10       0           1        1    14.9    15.3     2\n",
      "11       1           0        1    25.0    28.1     0\n",
      "...    ...         ...      ...     ...     ...   ...\n",
      "9990     0           1        2    19.2    19.9     1\n",
      "9991     0           1        1    25.1    26.2     2\n",
      "9993     0           1        3    13.7    14.1     2\n",
      "9996     0           0        1    22.3    22.2     0\n",
      "9997     0           0        1     9.6     9.7     0\n",
      "\n",
      "[4998 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "y = sh['y'].values.reshape(-1, 1)\n",
    "print(\"y 列的 NumPy 列向量: \\n\")\n",
    "print(y)\n",
    "sh = sh.drop(columns=['y'])\n",
    "print(\"\\n删除 'y' 列后的 数据:\")\n",
    "print(sh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. 数据预处理 V：请将DataFrame对象转换为Numpy数组，方便后续操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 使用 .to_numpy() 方法\n",
      "[[ 1.   1.   1.  21.1 25.   2. ]\n",
      " [ 0.   1.   1.  20.4 18.2  0. ]\n",
      " [ 0.   1.   3.  17.4 18.   3. ]\n",
      " ...\n",
      " [ 0.   1.   3.  13.7 14.1  2. ]\n",
      " [ 0.   0.   1.  22.3 22.2  0. ]\n",
      " [ 0.   0.   1.   9.6  9.7  0. ]]\n"
     ]
    }
   ],
   "source": [
    "array = sh.to_numpy()\n",
    "print(\"\\n 使用 .to_numpy() 方法\")\n",
    "print(array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. 数据集划分：请按照训练集与测试集8:2的比例将原始数据集划分。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(array, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. 数据预处理 VI：请分别对训练集数据、训练集标签、测试集数据和测试集标签进行归一化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始训练集特征 X_train:\n",
      "[[ 1.   1.   1.  22.2 25.1  3. ]\n",
      " [ 1.   1.   1.   1.3 -2.1  1. ]\n",
      " [ 1.   1.   1.  26.6 28.8  1. ]\n",
      " ...\n",
      " [ 1.   0.   1.  25.7 27.9  1. ]\n",
      " [ 1.   1.   1.  19.7 20.5  0. ]\n",
      " [ 1.   0.   1.   1.8 -2.5  2. ]]\n",
      "原始训练集标签 y_train:\n",
      "[[108]\n",
      " [ 22]\n",
      " [ 60]\n",
      " ...\n",
      " [108]\n",
      " [129]\n",
      " [  9]]\n",
      "原始测试集特征 X_test:\n",
      "[[ 0.   0.   1.   4.6  4.4  0. ]\n",
      " [ 0.   1.   2.  -0.1 -3.6  1. ]\n",
      " [ 1.   1.   1.  27.4 28.7  4. ]\n",
      " ...\n",
      " [ 1.   1.   1.  25.3 26.5  0. ]\n",
      " [ 1.   1.   1.  29.9 33.3  2. ]\n",
      " [ 1.   0.   1.  34.7 40.4  2. ]]\n",
      "原始测试集标签 y_test:\n",
      "[[  1]\n",
      " [  2]\n",
      " [ 61]\n",
      " [ 36]\n",
      " [  2]\n",
      " [169]\n",
      " [ 18]\n",
      " [ 29]\n",
      " [ 12]\n",
      " [ 16]\n",
      " [120]\n",
      " [122]\n",
      " [ 95]\n",
      " [  3]\n",
      " [ 33]\n",
      " [ 31]\n",
      " [ 66]\n",
      " [ 45]\n",
      " [162]\n",
      " [ 12]\n",
      " [ 27]\n",
      " [ 32]\n",
      " [  6]\n",
      " [  2]\n",
      " [ 69]\n",
      " [124]\n",
      " [ 12]\n",
      " [159]\n",
      " [ 92]\n",
      " [ 30]\n",
      " [ 62]\n",
      " [ 69]\n",
      " [ 46]\n",
      " [ 12]\n",
      " [  6]\n",
      " [  4]\n",
      " [ 59]\n",
      " [ 27]\n",
      " [ 47]\n",
      " [146]\n",
      " [ 34]\n",
      " [  1]\n",
      " [  3]\n",
      " [ 63]\n",
      " [  1]\n",
      " [ 56]\n",
      " [  0]\n",
      " [ 34]\n",
      " [  2]\n",
      " [  5]\n",
      " [ 38]\n",
      " [  2]\n",
      " [  9]\n",
      " [  6]\n",
      " [ 27]\n",
      " [ 27]\n",
      " [  8]\n",
      " [ 18]\n",
      " [ 45]\n",
      " [  3]\n",
      " [ 45]\n",
      " [  1]\n",
      " [ 54]\n",
      " [  1]\n",
      " [ 63]\n",
      " [ 40]\n",
      " [ 42]\n",
      " [ 48]\n",
      " [ 95]\n",
      " [ 17]\n",
      " [ 52]\n",
      " [ 22]\n",
      " [  2]\n",
      " [ 12]\n",
      " [100]\n",
      " [ 50]\n",
      " [ 85]\n",
      " [ 32]\n",
      " [  3]\n",
      " [123]\n",
      " [ 70]\n",
      " [ 50]\n",
      " [ 20]\n",
      " [104]\n",
      " [ 93]\n",
      " [ 48]\n",
      " [ 59]\n",
      " [ 33]\n",
      " [ 87]\n",
      " [  3]\n",
      " [ 64]\n",
      " [ 22]\n",
      " [ 21]\n",
      " [ 81]\n",
      " [ 84]\n",
      " [ 25]\n",
      " [ 60]\n",
      " [ 22]\n",
      " [  9]\n",
      " [  8]\n",
      " [  4]\n",
      " [ 27]\n",
      " [  2]\n",
      " [ 72]\n",
      " [  0]\n",
      " [ 78]\n",
      " [ 15]\n",
      " [ 19]\n",
      " [ 18]\n",
      " [  5]\n",
      " [  1]\n",
      " [106]\n",
      " [  8]\n",
      " [158]\n",
      " [ 21]\n",
      " [  4]\n",
      " [133]\n",
      " [ 21]\n",
      " [  4]\n",
      " [ 77]\n",
      " [ 94]\n",
      " [  2]\n",
      " [ 19]\n",
      " [ 31]\n",
      " [ 88]\n",
      " [165]\n",
      " [  8]\n",
      " [ 21]\n",
      " [ 52]\n",
      " [ 55]\n",
      " [ 25]\n",
      " [ 13]\n",
      " [  3]\n",
      " [  0]\n",
      " [ 24]\n",
      " [  6]\n",
      " [  1]\n",
      " [  9]\n",
      " [ 33]\n",
      " [ 50]\n",
      " [  2]\n",
      " [  1]\n",
      " [ 70]\n",
      " [  7]\n",
      " [ 45]\n",
      " [ 12]\n",
      " [ 27]\n",
      " [ 75]\n",
      " [ 67]\n",
      " [  5]\n",
      " [  0]\n",
      " [127]\n",
      " [ 86]\n",
      " [ 48]\n",
      " [ 27]\n",
      " [ 23]\n",
      " [ 74]\n",
      " [ 97]\n",
      " [112]\n",
      " [ 43]\n",
      " [ 27]\n",
      " [ 35]\n",
      " [  3]\n",
      " [ 37]\n",
      " [  2]\n",
      " [ 44]\n",
      " [ 97]\n",
      " [ 26]\n",
      " [ 46]\n",
      " [ 76]\n",
      " [  8]\n",
      " [  2]\n",
      " [  7]\n",
      " [ 10]\n",
      " [  6]\n",
      " [ 79]\n",
      " [ 59]\n",
      " [ 27]\n",
      " [ 20]\n",
      " [ 10]\n",
      " [  3]\n",
      " [ 92]\n",
      " [ 74]\n",
      " [ 72]\n",
      " [ 72]\n",
      " [  0]\n",
      " [ 49]\n",
      " [ 42]\n",
      " [  1]\n",
      " [ 43]\n",
      " [ 39]\n",
      " [  3]\n",
      " [113]\n",
      " [ 51]\n",
      " [153]\n",
      " [134]\n",
      " [ 20]\n",
      " [ 82]\n",
      " [  0]\n",
      " [  0]\n",
      " [  0]\n",
      " [ 83]\n",
      " [138]\n",
      " [ 17]\n",
      " [  4]\n",
      " [129]\n",
      " [  3]\n",
      " [ 36]\n",
      " [  0]\n",
      " [ 18]\n",
      " [ 30]\n",
      " [  9]\n",
      " [ 20]\n",
      " [112]\n",
      " [  7]\n",
      " [  0]\n",
      " [ 12]\n",
      " [  7]\n",
      " [  1]\n",
      " [  1]\n",
      " [ 27]\n",
      " [  1]\n",
      " [ 31]\n",
      " [ 84]\n",
      " [ 66]\n",
      " [ 29]\n",
      " [  1]\n",
      " [ 53]\n",
      " [  6]\n",
      " [ 69]\n",
      " [ 49]\n",
      " [ 68]\n",
      " [125]\n",
      " [ 62]\n",
      " [ 60]\n",
      " [ 57]\n",
      " [ 82]\n",
      " [ 23]\n",
      " [ 36]\n",
      " [ 23]\n",
      " [  6]\n",
      " [ 23]\n",
      " [ 74]\n",
      " [  4]\n",
      " [117]\n",
      " [ 85]\n",
      " [ 25]\n",
      " [ 91]\n",
      " [106]\n",
      " [147]\n",
      " [ 17]\n",
      " [ 32]\n",
      " [ 14]\n",
      " [ 71]\n",
      " [123]\n",
      " [ 49]\n",
      " [ 78]\n",
      " [  9]\n",
      " [139]\n",
      " [ 30]\n",
      " [ 29]\n",
      " [  7]\n",
      " [  0]\n",
      " [  0]\n",
      " [135]\n",
      " [ 50]\n",
      " [  1]\n",
      " [  1]\n",
      " [  0]\n",
      " [ 51]\n",
      " [126]\n",
      " [  1]\n",
      " [ 97]\n",
      " [ 89]\n",
      " [ 54]\n",
      " [  5]\n",
      " [ 16]\n",
      " [ 61]\n",
      " [ 20]\n",
      " [  6]\n",
      " [ 91]\n",
      " [ 36]\n",
      " [ 43]\n",
      " [ 93]\n",
      " [ 73]\n",
      " [ 73]\n",
      " [ 51]\n",
      " [ 30]\n",
      " [135]\n",
      " [ 15]\n",
      " [ 15]\n",
      " [ 82]\n",
      " [  1]\n",
      " [124]\n",
      " [ 14]\n",
      " [ 60]\n",
      " [ 45]\n",
      " [ 26]\n",
      " [  8]\n",
      " [114]\n",
      " [ 39]\n",
      " [ 99]\n",
      " [105]\n",
      " [ 26]\n",
      " [ 26]\n",
      " [ 51]\n",
      " [ 28]\n",
      " [158]\n",
      " [128]\n",
      " [102]\n",
      " [ 95]\n",
      " [ 36]\n",
      " [ 41]\n",
      " [ 24]\n",
      " [107]\n",
      " [ 72]\n",
      " [ 56]\n",
      " [ 62]\n",
      " [  2]\n",
      " [ 39]\n",
      " [ 95]\n",
      " [ 91]\n",
      " [ 74]\n",
      " [101]\n",
      " [ 13]\n",
      " [  6]\n",
      " [175]\n",
      " [ 45]\n",
      " [ 35]\n",
      " [  4]\n",
      " [149]\n",
      " [ 60]\n",
      " [110]\n",
      " [109]\n",
      " [  2]\n",
      " [ 71]\n",
      " [136]\n",
      " [101]\n",
      " [ 45]\n",
      " [151]\n",
      " [ 39]\n",
      " [ 20]\n",
      " [ 18]\n",
      " [ 60]\n",
      " [  3]\n",
      " [ 16]\n",
      " [  5]\n",
      " [ 99]\n",
      " [ 86]\n",
      " [132]\n",
      " [  4]\n",
      " [ 31]\n",
      " [ 63]\n",
      " [106]\n",
      " [ 54]\n",
      " [ 57]\n",
      " [ 60]\n",
      " [ 87]\n",
      " [  0]\n",
      " [116]\n",
      " [ 49]\n",
      " [ 45]\n",
      " [ 24]\n",
      " [  5]\n",
      " [ 95]\n",
      " [115]\n",
      " [ 80]\n",
      " [ 53]\n",
      " [  9]\n",
      " [ 41]\n",
      " [  3]\n",
      " [  1]\n",
      " [  5]\n",
      " [ 41]\n",
      " [ 68]\n",
      " [ 24]\n",
      " [ 39]\n",
      " [ 25]\n",
      " [ 18]\n",
      " [  1]\n",
      " [125]\n",
      " [  1]\n",
      " [ 66]\n",
      " [ 45]\n",
      " [ 21]\n",
      " [ 44]\n",
      " [ 40]\n",
      " [ 17]\n",
      " [132]\n",
      " [ 81]\n",
      " [ 25]\n",
      " [ 34]\n",
      " [ 11]\n",
      " [  7]\n",
      " [ 31]\n",
      " [ 61]\n",
      " [ 50]\n",
      " [ 18]\n",
      " [ 44]\n",
      " [166]\n",
      " [  3]\n",
      " [ 74]\n",
      " [ 21]\n",
      " [ 37]\n",
      " [ 38]\n",
      " [  3]\n",
      " [  6]\n",
      " [ 92]\n",
      " [  3]\n",
      " [  7]\n",
      " [  0]\n",
      " [  3]\n",
      " [121]\n",
      " [  7]\n",
      " [119]\n",
      " [  0]\n",
      " [ 47]\n",
      " [  4]\n",
      " [ 46]\n",
      " [ 61]\n",
      " [ 38]\n",
      " [  0]\n",
      " [ 51]\n",
      " [ 34]\n",
      " [ 55]\n",
      " [  1]\n",
      " [  7]\n",
      " [  0]\n",
      " [ 49]\n",
      " [ 86]\n",
      " [  3]\n",
      " [ 72]\n",
      " [ 37]\n",
      " [ 61]\n",
      " [ 38]\n",
      " [ 47]\n",
      " [ 34]\n",
      " [ 39]\n",
      " [105]\n",
      " [  0]\n",
      " [ 67]\n",
      " [ 58]\n",
      " [ 52]\n",
      " [ 39]\n",
      " [ 63]\n",
      " [  3]\n",
      " [ 37]\n",
      " [  7]\n",
      " [ 10]\n",
      " [ 47]\n",
      " [ 25]\n",
      " [ 10]\n",
      " [ 35]\n",
      " [ 42]\n",
      " [ 45]\n",
      " [ 19]\n",
      " [108]\n",
      " [ 38]\n",
      " [ 50]\n",
      " [113]\n",
      " [ 27]\n",
      " [ 39]\n",
      " [ 82]\n",
      " [ 16]\n",
      " [ 18]\n",
      " [  7]\n",
      " [ 39]\n",
      " [ 13]\n",
      " [ 66]\n",
      " [ 29]\n",
      " [ 13]\n",
      " [ 50]\n",
      " [ 40]\n",
      " [ 98]\n",
      " [  3]\n",
      " [ 26]\n",
      " [ 33]\n",
      " [ 24]\n",
      " [ 60]\n",
      " [102]\n",
      " [ 55]\n",
      " [ 55]\n",
      " [ 23]\n",
      " [  3]\n",
      " [ 64]\n",
      " [ 23]\n",
      " [  3]\n",
      " [  6]\n",
      " [  8]\n",
      " [ 41]\n",
      " [ 15]\n",
      " [ 39]\n",
      " [ 55]\n",
      " [ 67]\n",
      " [ 17]\n",
      " [ 38]\n",
      " [ 36]\n",
      " [ 55]\n",
      " [ 15]\n",
      " [ 46]\n",
      " [111]\n",
      " [  1]\n",
      " [  1]\n",
      " [ 25]\n",
      " [ 27]\n",
      " [  0]\n",
      " [ 18]\n",
      " [ 15]\n",
      " [102]\n",
      " [  1]\n",
      " [  6]\n",
      " [ 20]\n",
      " [ 24]\n",
      " [ 32]\n",
      " [  5]\n",
      " [ 26]\n",
      " [  5]\n",
      " [ 92]\n",
      " [ 13]\n",
      " [ 19]\n",
      " [ 32]\n",
      " [132]\n",
      " [ 57]\n",
      " [ 72]\n",
      " [ 19]\n",
      " [ 61]\n",
      " [ 57]\n",
      " [  5]\n",
      " [126]\n",
      " [  1]\n",
      " [ 48]\n",
      " [  8]\n",
      " [ 46]\n",
      " [ 15]\n",
      " [ 72]\n",
      " [ 20]\n",
      " [ 29]\n",
      " [ 60]\n",
      " [ 81]\n",
      " [  4]\n",
      " [  5]\n",
      " [  0]\n",
      " [  4]\n",
      " [  8]\n",
      " [  9]\n",
      " [ 39]\n",
      " [ 48]\n",
      " [117]\n",
      " [  5]\n",
      " [ 26]\n",
      " [  0]\n",
      " [ 30]\n",
      " [122]\n",
      " [ 70]\n",
      " [ 18]\n",
      " [ 76]\n",
      " [ 15]\n",
      " [  1]\n",
      " [ 36]\n",
      " [ 15]\n",
      " [ 52]\n",
      " [ 35]\n",
      " [  0]\n",
      " [ 78]\n",
      " [ 30]\n",
      " [119]\n",
      " [ 44]\n",
      " [  0]\n",
      " [ 36]\n",
      " [  0]\n",
      " [ 17]\n",
      " [ 67]\n",
      " [ 26]\n",
      " [ 54]\n",
      " [ 30]\n",
      " [  3]\n",
      " [ 44]\n",
      " [ 10]\n",
      " [ 70]\n",
      " [ 51]\n",
      " [ 19]\n",
      " [  1]\n",
      " [  3]\n",
      " [ 26]\n",
      " [  0]\n",
      " [  1]\n",
      " [  6]\n",
      " [ 21]\n",
      " [ 56]\n",
      " [ 63]\n",
      " [ 51]\n",
      " [ 15]\n",
      " [ 58]\n",
      " [ 26]\n",
      " [ 36]\n",
      " [ 21]\n",
      " [  6]\n",
      " [ 58]\n",
      " [ 99]\n",
      " [  8]\n",
      " [ 85]\n",
      " [  9]\n",
      " [ 15]\n",
      " [ 12]\n",
      " [ 13]\n",
      " [ 14]\n",
      " [ 45]\n",
      " [  2]\n",
      " [ 62]\n",
      " [ 39]\n",
      " [ 10]\n",
      " [  9]\n",
      " [  0]\n",
      " [ 22]\n",
      " [  8]\n",
      " [ 53]\n",
      " [ 28]\n",
      " [ 29]\n",
      " [ 90]\n",
      " [ 41]\n",
      " [  1]\n",
      " [  0]\n",
      " [ 16]\n",
      " [  3]\n",
      " [  3]\n",
      " [ 42]\n",
      " [  3]\n",
      " [171]\n",
      " [ 31]\n",
      " [ 88]\n",
      " [ 51]\n",
      " [ 38]\n",
      " [ 56]\n",
      " [ 46]\n",
      " [111]\n",
      " [  1]\n",
      " [ 28]\n",
      " [ 74]\n",
      " [  5]\n",
      " [ 26]\n",
      " [ 62]\n",
      " [ 51]\n",
      " [ 31]\n",
      " [  9]\n",
      " [ 84]\n",
      " [  3]\n",
      " [ 29]\n",
      " [126]\n",
      " [159]\n",
      " [  5]\n",
      " [ 21]\n",
      " [  3]\n",
      " [ 20]\n",
      " [  0]\n",
      " [141]\n",
      " [ 81]\n",
      " [163]\n",
      " [ 87]\n",
      " [ 48]\n",
      " [115]\n",
      " [100]\n",
      " [  1]\n",
      " [ 21]\n",
      " [ 43]\n",
      " [  6]\n",
      " [  6]\n",
      " [ 54]\n",
      " [172]\n",
      " [  2]\n",
      " [ 45]\n",
      " [  4]\n",
      " [183]\n",
      " [ 17]\n",
      " [  0]\n",
      " [ 41]\n",
      " [  3]\n",
      " [ 66]\n",
      " [ 70]\n",
      " [ 20]\n",
      " [  7]\n",
      " [ 33]\n",
      " [ 70]\n",
      " [ 85]\n",
      " [  6]\n",
      " [ 23]\n",
      " [ 44]\n",
      " [ 28]\n",
      " [111]\n",
      " [133]\n",
      " [ 28]\n",
      " [ 12]\n",
      " [ 50]\n",
      " [ 41]\n",
      " [ 44]\n",
      " [ 67]\n",
      " [  0]\n",
      " [ 96]\n",
      " [ 53]\n",
      " [ 93]\n",
      " [109]\n",
      " [  3]\n",
      " [ 42]\n",
      " [ 91]\n",
      " [ 56]\n",
      " [ 24]\n",
      " [ 58]\n",
      " [ 60]\n",
      " [ 49]\n",
      " [ 51]\n",
      " [ 59]\n",
      " [  6]\n",
      " [  5]\n",
      " [111]\n",
      " [ 35]\n",
      " [ 99]\n",
      " [  8]\n",
      " [ 21]\n",
      " [ 44]\n",
      " [ 45]\n",
      " [ 11]\n",
      " [107]\n",
      " [ 20]\n",
      " [  3]\n",
      " [ 47]\n",
      " [ 65]\n",
      " [ 13]\n",
      " [132]\n",
      " [  3]\n",
      " [ 13]\n",
      " [  1]\n",
      " [ 78]\n",
      " [ 60]\n",
      " [ 42]\n",
      " [  4]\n",
      " [ 28]\n",
      " [ 68]\n",
      " [ 56]\n",
      " [ 38]\n",
      " [  7]\n",
      " [106]\n",
      " [  6]\n",
      " [  9]\n",
      " [ 61]\n",
      " [ 12]\n",
      " [ 42]\n",
      " [  2]\n",
      " [  0]\n",
      " [ 46]\n",
      " [ 54]\n",
      " [ 21]\n",
      " [ 96]\n",
      " [ 81]\n",
      " [ 33]\n",
      " [ 11]\n",
      " [ 54]\n",
      " [ 34]\n",
      " [ 41]\n",
      " [  3]\n",
      " [  0]\n",
      " [ 54]\n",
      " [ 15]\n",
      " [ 33]\n",
      " [ 58]\n",
      " [121]\n",
      " [ 37]\n",
      " [ 64]\n",
      " [ 54]\n",
      " [  5]\n",
      " [  7]\n",
      " [ 16]\n",
      " [159]\n",
      " [110]\n",
      " [ 27]\n",
      " [  1]\n",
      " [ 22]\n",
      " [ 51]\n",
      " [  3]\n",
      " [ 15]\n",
      " [ 91]\n",
      " [122]\n",
      " [  9]\n",
      " [ 35]\n",
      " [  5]\n",
      " [ 19]\n",
      " [179]\n",
      " [ 34]\n",
      " [ 44]\n",
      " [107]\n",
      " [  1]\n",
      " [ 42]\n",
      " [ 36]\n",
      " [ 51]\n",
      " [ 79]\n",
      " [ 21]\n",
      " [  6]\n",
      " [  6]\n",
      " [  7]\n",
      " [119]\n",
      " [133]\n",
      " [ 26]\n",
      " [  0]\n",
      " [  1]\n",
      " [  3]\n",
      " [ 13]\n",
      " [ 39]\n",
      " [ 39]\n",
      " [ 64]\n",
      " [107]\n",
      " [  9]\n",
      " [  1]\n",
      " [ 44]\n",
      " [  3]\n",
      " [  9]\n",
      " [  1]\n",
      " [138]\n",
      " [ 36]\n",
      " [ 52]\n",
      " [ 52]\n",
      " [ 49]\n",
      " [  3]\n",
      " [ 45]\n",
      " [ 33]\n",
      " [  3]\n",
      " [ 32]\n",
      " [  4]\n",
      " [  1]\n",
      " [ 59]\n",
      " [ 19]\n",
      " [  3]\n",
      " [118]\n",
      " [ 19]\n",
      " [ 81]\n",
      " [  6]\n",
      " [ 63]\n",
      " [ 10]\n",
      " [ 86]\n",
      " [ 67]\n",
      " [ 75]\n",
      " [  3]\n",
      " [ 69]\n",
      " [ 11]\n",
      " [ 30]\n",
      " [  9]\n",
      " [ 61]\n",
      " [ 33]\n",
      " [  5]\n",
      " [ 19]\n",
      " [  1]\n",
      " [ 21]\n",
      " [ 28]\n",
      " [ 86]\n",
      " [ 11]\n",
      " [ 94]\n",
      " [ 20]\n",
      " [ 23]\n",
      " [  2]\n",
      " [  5]\n",
      " [ 53]\n",
      " [112]\n",
      " [ 25]\n",
      " [ 48]\n",
      " [104]\n",
      " [ 36]\n",
      " [ 26]\n",
      " [ 60]\n",
      " [ 18]\n",
      " [ 50]\n",
      " [123]\n",
      " [  1]\n",
      " [ 42]\n",
      " [ 66]\n",
      " [ 51]\n",
      " [121]\n",
      " [ 13]\n",
      " [ 10]\n",
      " [ 34]\n",
      " [ 31]\n",
      " [ 22]\n",
      " [ 12]\n",
      " [  1]\n",
      " [ 30]\n",
      " [ 33]\n",
      " [ 29]\n",
      " [ 17]\n",
      " [  9]\n",
      " [ 41]\n",
      " [ 64]\n",
      " [ 36]\n",
      " [ 21]\n",
      " [ 10]\n",
      " [ 87]\n",
      " [ 10]\n",
      " [  4]\n",
      " [  9]\n",
      " [ 56]\n",
      " [  7]\n",
      " [  2]\n",
      " [ 76]\n",
      " [ 16]\n",
      " [  3]\n",
      " [ 27]\n",
      " [ 34]\n",
      " [ 38]\n",
      " [ 24]\n",
      " [ 66]\n",
      " [119]\n",
      " [ 26]\n",
      " [  0]\n",
      " [  8]\n",
      " [101]\n",
      " [  2]\n",
      " [ 76]\n",
      " [  3]\n",
      " [  0]\n",
      " [ 35]\n",
      " [ 12]\n",
      " [ 55]\n",
      " [ 26]\n",
      " [ 10]\n",
      " [  3]\n",
      " [ 67]\n",
      " [ 41]\n",
      " [ 84]\n",
      " [ 75]\n",
      " [ 83]\n",
      " [ 54]\n",
      " [ 25]\n",
      " [ 53]\n",
      " [ 64]\n",
      " [111]\n",
      " [102]\n",
      " [ 10]\n",
      " [ 42]\n",
      " [ 67]\n",
      " [ 11]\n",
      " [ 42]\n",
      " [  4]\n",
      " [ 47]\n",
      " [130]\n",
      " [117]\n",
      " [125]\n",
      " [  1]\n",
      " [  0]\n",
      " [ 38]\n",
      " [ 55]\n",
      " [ 33]\n",
      " [ 58]\n",
      " [ 85]\n",
      " [149]\n",
      " [ 77]\n",
      " [ 99]\n",
      " [ 70]\n",
      " [129]\n",
      " [ 26]\n",
      " [ 55]\n",
      " [ 42]\n",
      " [  7]\n",
      " [  9]\n",
      " [ 64]\n",
      " [ 49]\n",
      " [ 18]\n",
      " [  8]\n",
      " [ 76]\n",
      " [ 47]\n",
      " [ 67]\n",
      " [  7]\n",
      " [ 30]\n",
      " [ 48]\n",
      " [170]\n",
      " [ 27]\n",
      " [ 69]\n",
      " [ 57]\n",
      " [ 56]\n",
      " [  3]\n",
      " [  3]\n",
      " [  0]\n",
      " [ 28]\n",
      " [  2]\n",
      " [  6]\n",
      " [  0]\n",
      " [ 37]\n",
      " [  7]\n",
      " [ 42]\n",
      " [ 15]\n",
      " [112]\n",
      " [ 11]\n",
      " [  7]\n",
      " [ 44]\n",
      " [ 69]\n",
      " [ 41]\n",
      " [ 85]\n",
      " [ 15]\n",
      " [111]\n",
      " [  5]\n",
      " [ 41]\n",
      " [ 18]\n",
      " [ 31]\n",
      " [195]\n",
      " [ 99]\n",
      " [ 74]]\n",
      "\n",
      "归一化后的训练集特征 X_train_scaled:\n",
      "[[1.         1.         0.         0.66063348 0.65224359 0.42857143]\n",
      " [1.         1.         0.         0.18778281 0.21634615 0.14285714]\n",
      " [1.         1.         0.         0.760181   0.71153846 0.14285714]\n",
      " ...\n",
      " [1.         0.         0.         0.739819   0.69711538 0.14285714]\n",
      " [1.         1.         0.         0.6040724  0.57852564 0.        ]\n",
      " [1.         0.         0.         0.19909502 0.2099359  0.28571429]]\n",
      "\n",
      "归一化后的训练集标签 y_train_scaled:\n",
      "[0.56544503 0.11518325 0.31413613 ... 0.56544503 0.67539267 0.04712042]\n",
      "\n",
      "归一化后的测试集特征 X_test_scaled:\n",
      "[[0.         0.         0.         0.26244344 0.32051282 0.        ]\n",
      " [0.         1.         0.5        0.1561086  0.19230769 0.14285714]\n",
      " [1.         1.         0.         0.77828054 0.7099359  0.57142857]\n",
      " ...\n",
      " [1.         1.         0.         0.73076923 0.67467949 0.        ]\n",
      " [1.         1.         0.         0.83484163 0.78365385 0.28571429]\n",
      " [1.         0.         0.         0.94343891 0.8974359  0.28571429]]\n",
      "\n",
      "归一化后的测试集标签 y_test_scaled:\n",
      "[0.0052356  0.0104712  0.31937173 0.18848168 0.0104712  0.88481675\n",
      " 0.09424084 0.15183246 0.06282723 0.08376963 0.62827225 0.63874346\n",
      " 0.4973822  0.01570681 0.17277487 0.16230366 0.34554974 0.23560209\n",
      " 0.84816754 0.06282723 0.14136126 0.16753927 0.03141361 0.0104712\n",
      " 0.36125654 0.64921466 0.06282723 0.83246073 0.48167539 0.15706806\n",
      " 0.32460733 0.36125654 0.2408377  0.06282723 0.03141361 0.02094241\n",
      " 0.30890052 0.14136126 0.2460733  0.76439791 0.17801047 0.0052356\n",
      " 0.01570681 0.32984293 0.0052356  0.29319372 0.         0.17801047\n",
      " 0.0104712  0.02617801 0.19895288 0.0104712  0.04712042 0.03141361\n",
      " 0.14136126 0.14136126 0.04188482 0.09424084 0.23560209 0.01570681\n",
      " 0.23560209 0.0052356  0.28272251 0.0052356  0.32984293 0.20942408\n",
      " 0.21989529 0.2513089  0.4973822  0.08900524 0.27225131 0.11518325\n",
      " 0.0104712  0.06282723 0.52356021 0.2617801  0.44502618 0.16753927\n",
      " 0.01570681 0.64397906 0.36649215 0.2617801  0.10471204 0.54450262\n",
      " 0.48691099 0.2513089  0.30890052 0.17277487 0.45549738 0.01570681\n",
      " 0.33507853 0.11518325 0.10994764 0.42408377 0.43979058 0.13089005\n",
      " 0.31413613 0.11518325 0.04712042 0.04188482 0.02094241 0.14136126\n",
      " 0.0104712  0.37696335 0.         0.40837696 0.07853403 0.09947644\n",
      " 0.09424084 0.02617801 0.0052356  0.55497382 0.04188482 0.82722513\n",
      " 0.10994764 0.02094241 0.69633508 0.10994764 0.02094241 0.40314136\n",
      " 0.4921466  0.0104712  0.09947644 0.16230366 0.46073298 0.86387435\n",
      " 0.04188482 0.10994764 0.27225131 0.28795812 0.13089005 0.06806283\n",
      " 0.01570681 0.         0.12565445 0.03141361 0.0052356  0.04712042\n",
      " 0.17277487 0.2617801  0.0104712  0.0052356  0.36649215 0.03664921\n",
      " 0.23560209 0.06282723 0.14136126 0.39267016 0.35078534 0.02617801\n",
      " 0.         0.66492147 0.45026178 0.2513089  0.14136126 0.12041885\n",
      " 0.38743455 0.5078534  0.58638743 0.22513089 0.14136126 0.18324607\n",
      " 0.01570681 0.19371728 0.0104712  0.23036649 0.5078534  0.13612565\n",
      " 0.2408377  0.39790576 0.04188482 0.0104712  0.03664921 0.05235602\n",
      " 0.03141361 0.41361257 0.30890052 0.14136126 0.10471204 0.05235602\n",
      " 0.01570681 0.48167539 0.38743455 0.37696335 0.37696335 0.\n",
      " 0.2565445  0.21989529 0.0052356  0.22513089 0.20418848 0.01570681\n",
      " 0.59162304 0.26701571 0.80104712 0.70157068 0.10471204 0.42931937\n",
      " 0.         0.         0.         0.43455497 0.72251309 0.08900524\n",
      " 0.02094241 0.67539267 0.01570681 0.18848168 0.         0.09424084\n",
      " 0.15706806 0.04712042 0.10471204 0.58638743 0.03664921 0.\n",
      " 0.06282723 0.03664921 0.0052356  0.0052356  0.14136126 0.0052356\n",
      " 0.16230366 0.43979058 0.34554974 0.15183246 0.0052356  0.27748691\n",
      " 0.03141361 0.36125654 0.2565445  0.35602094 0.65445026 0.32460733\n",
      " 0.31413613 0.29842932 0.42931937 0.12041885 0.18848168 0.12041885\n",
      " 0.03141361 0.12041885 0.38743455 0.02094241 0.61256545 0.44502618\n",
      " 0.13089005 0.47643979 0.55497382 0.76963351 0.08900524 0.16753927\n",
      " 0.07329843 0.37172775 0.64397906 0.2565445  0.40837696 0.04712042\n",
      " 0.72774869 0.15706806 0.15183246 0.03664921 0.         0.\n",
      " 0.70680628 0.2617801  0.0052356  0.0052356  0.         0.26701571\n",
      " 0.65968586 0.0052356  0.5078534  0.46596859 0.28272251 0.02617801\n",
      " 0.08376963 0.31937173 0.10471204 0.03141361 0.47643979 0.18848168\n",
      " 0.22513089 0.48691099 0.38219895 0.38219895 0.26701571 0.15706806\n",
      " 0.70680628 0.07853403 0.07853403 0.42931937 0.0052356  0.64921466\n",
      " 0.07329843 0.31413613 0.23560209 0.13612565 0.04188482 0.59685864\n",
      " 0.20418848 0.51832461 0.54973822 0.13612565 0.13612565 0.26701571\n",
      " 0.14659686 0.82722513 0.67015707 0.53403141 0.4973822  0.18848168\n",
      " 0.21465969 0.12565445 0.56020942 0.37696335 0.29319372 0.32460733\n",
      " 0.0104712  0.20418848 0.4973822  0.47643979 0.38743455 0.52879581\n",
      " 0.06806283 0.03141361 0.91623037 0.23560209 0.18324607 0.02094241\n",
      " 0.78010471 0.31413613 0.57591623 0.57068063 0.0104712  0.37172775\n",
      " 0.71204188 0.52879581 0.23560209 0.79057592 0.20418848 0.10471204\n",
      " 0.09424084 0.31413613 0.01570681 0.08376963 0.02617801 0.51832461\n",
      " 0.45026178 0.69109948 0.02094241 0.16230366 0.32984293 0.55497382\n",
      " 0.28272251 0.29842932 0.31413613 0.45549738 0.         0.60732984\n",
      " 0.2565445  0.23560209 0.12565445 0.02617801 0.4973822  0.60209424\n",
      " 0.41884817 0.27748691 0.04712042 0.21465969 0.01570681 0.0052356\n",
      " 0.02617801 0.21465969 0.35602094 0.12565445 0.20418848 0.13089005\n",
      " 0.09424084 0.0052356  0.65445026 0.0052356  0.34554974 0.23560209\n",
      " 0.10994764 0.23036649 0.20942408 0.08900524 0.69109948 0.42408377\n",
      " 0.13089005 0.17801047 0.05759162 0.03664921 0.16230366 0.31937173\n",
      " 0.2617801  0.09424084 0.23036649 0.86910995 0.01570681 0.38743455\n",
      " 0.10994764 0.19371728 0.19895288 0.01570681 0.03141361 0.48167539\n",
      " 0.01570681 0.03664921 0.         0.01570681 0.63350785 0.03664921\n",
      " 0.62303665 0.         0.2460733  0.02094241 0.2408377  0.31937173\n",
      " 0.19895288 0.         0.26701571 0.17801047 0.28795812 0.0052356\n",
      " 0.03664921 0.         0.2565445  0.45026178 0.01570681 0.37696335\n",
      " 0.19371728 0.31937173 0.19895288 0.2460733  0.17801047 0.20418848\n",
      " 0.54973822 0.         0.35078534 0.30366492 0.27225131 0.20418848\n",
      " 0.32984293 0.01570681 0.19371728 0.03664921 0.05235602 0.2460733\n",
      " 0.13089005 0.05235602 0.18324607 0.21989529 0.23560209 0.09947644\n",
      " 0.56544503 0.19895288 0.2617801  0.59162304 0.14136126 0.20418848\n",
      " 0.42931937 0.08376963 0.09424084 0.03664921 0.20418848 0.06806283\n",
      " 0.34554974 0.15183246 0.06806283 0.2617801  0.20942408 0.51308901\n",
      " 0.01570681 0.13612565 0.17277487 0.12565445 0.31413613 0.53403141\n",
      " 0.28795812 0.28795812 0.12041885 0.01570681 0.33507853 0.12041885\n",
      " 0.01570681 0.03141361 0.04188482 0.21465969 0.07853403 0.20418848\n",
      " 0.28795812 0.35078534 0.08900524 0.19895288 0.18848168 0.28795812\n",
      " 0.07853403 0.2408377  0.58115183 0.0052356  0.0052356  0.13089005\n",
      " 0.14136126 0.         0.09424084 0.07853403 0.53403141 0.0052356\n",
      " 0.03141361 0.10471204 0.12565445 0.16753927 0.02617801 0.13612565\n",
      " 0.02617801 0.48167539 0.06806283 0.09947644 0.16753927 0.69109948\n",
      " 0.29842932 0.37696335 0.09947644 0.31937173 0.29842932 0.02617801\n",
      " 0.65968586 0.0052356  0.2513089  0.04188482 0.2408377  0.07853403\n",
      " 0.37696335 0.10471204 0.15183246 0.31413613 0.42408377 0.02094241\n",
      " 0.02617801 0.         0.02094241 0.04188482 0.04712042 0.20418848\n",
      " 0.2513089  0.61256545 0.02617801 0.13612565 0.         0.15706806\n",
      " 0.63874346 0.36649215 0.09424084 0.39790576 0.07853403 0.0052356\n",
      " 0.18848168 0.07853403 0.27225131 0.18324607 0.         0.40837696\n",
      " 0.15706806 0.62303665 0.23036649 0.         0.18848168 0.\n",
      " 0.08900524 0.35078534 0.13612565 0.28272251 0.15706806 0.01570681\n",
      " 0.23036649 0.05235602 0.36649215 0.26701571 0.09947644 0.0052356\n",
      " 0.01570681 0.13612565 0.         0.0052356  0.03141361 0.10994764\n",
      " 0.29319372 0.32984293 0.26701571 0.07853403 0.30366492 0.13612565\n",
      " 0.18848168 0.10994764 0.03141361 0.30366492 0.51832461 0.04188482\n",
      " 0.44502618 0.04712042 0.07853403 0.06282723 0.06806283 0.07329843\n",
      " 0.23560209 0.0104712  0.32460733 0.20418848 0.05235602 0.04712042\n",
      " 0.         0.11518325 0.04188482 0.27748691 0.14659686 0.15183246\n",
      " 0.47120419 0.21465969 0.0052356  0.         0.08376963 0.01570681\n",
      " 0.01570681 0.21989529 0.01570681 0.89528796 0.16230366 0.46073298\n",
      " 0.26701571 0.19895288 0.29319372 0.2408377  0.58115183 0.0052356\n",
      " 0.14659686 0.38743455 0.02617801 0.13612565 0.32460733 0.26701571\n",
      " 0.16230366 0.04712042 0.43979058 0.01570681 0.15183246 0.65968586\n",
      " 0.83246073 0.02617801 0.10994764 0.01570681 0.10471204 0.\n",
      " 0.7382199  0.42408377 0.85340314 0.45549738 0.2513089  0.60209424\n",
      " 0.52356021 0.0052356  0.10994764 0.22513089 0.03141361 0.03141361\n",
      " 0.28272251 0.90052356 0.0104712  0.23560209 0.02094241 0.95811518\n",
      " 0.08900524 0.         0.21465969 0.01570681 0.34554974 0.36649215\n",
      " 0.10471204 0.03664921 0.17277487 0.36649215 0.44502618 0.03141361\n",
      " 0.12041885 0.23036649 0.14659686 0.58115183 0.69633508 0.14659686\n",
      " 0.06282723 0.2617801  0.21465969 0.23036649 0.35078534 0.\n",
      " 0.5026178  0.27748691 0.48691099 0.57068063 0.01570681 0.21989529\n",
      " 0.47643979 0.29319372 0.12565445 0.30366492 0.31413613 0.2565445\n",
      " 0.26701571 0.30890052 0.03141361 0.02617801 0.58115183 0.18324607\n",
      " 0.51832461 0.04188482 0.10994764 0.23036649 0.23560209 0.05759162\n",
      " 0.56020942 0.10471204 0.01570681 0.2460733  0.34031414 0.06806283\n",
      " 0.69109948 0.01570681 0.06806283 0.0052356  0.40837696 0.31413613\n",
      " 0.21989529 0.02094241 0.14659686 0.35602094 0.29319372 0.19895288\n",
      " 0.03664921 0.55497382 0.03141361 0.04712042 0.31937173 0.06282723\n",
      " 0.21989529 0.0104712  0.         0.2408377  0.28272251 0.10994764\n",
      " 0.5026178  0.42408377 0.17277487 0.05759162 0.28272251 0.17801047\n",
      " 0.21465969 0.01570681 0.         0.28272251 0.07853403 0.17277487\n",
      " 0.30366492 0.63350785 0.19371728 0.33507853 0.28272251 0.02617801\n",
      " 0.03664921 0.08376963 0.83246073 0.57591623 0.14136126 0.0052356\n",
      " 0.11518325 0.26701571 0.01570681 0.07853403 0.47643979 0.63874346\n",
      " 0.04712042 0.18324607 0.02617801 0.09947644 0.93717277 0.17801047\n",
      " 0.23036649 0.56020942 0.0052356  0.21989529 0.18848168 0.26701571\n",
      " 0.41361257 0.10994764 0.03141361 0.03141361 0.03664921 0.62303665\n",
      " 0.69633508 0.13612565 0.         0.0052356  0.01570681 0.06806283\n",
      " 0.20418848 0.20418848 0.33507853 0.56020942 0.04712042 0.0052356\n",
      " 0.23036649 0.01570681 0.04712042 0.0052356  0.72251309 0.18848168\n",
      " 0.27225131 0.27225131 0.2565445  0.01570681 0.23560209 0.17277487\n",
      " 0.01570681 0.16753927 0.02094241 0.0052356  0.30890052 0.09947644\n",
      " 0.01570681 0.61780105 0.09947644 0.42408377 0.03141361 0.32984293\n",
      " 0.05235602 0.45026178 0.35078534 0.39267016 0.01570681 0.36125654\n",
      " 0.05759162 0.15706806 0.04712042 0.31937173 0.17277487 0.02617801\n",
      " 0.09947644 0.0052356  0.10994764 0.14659686 0.45026178 0.05759162\n",
      " 0.4921466  0.10471204 0.12041885 0.0104712  0.02617801 0.27748691\n",
      " 0.58638743 0.13089005 0.2513089  0.54450262 0.18848168 0.13612565\n",
      " 0.31413613 0.09424084 0.2617801  0.64397906 0.0052356  0.21989529\n",
      " 0.34554974 0.26701571 0.63350785 0.06806283 0.05235602 0.17801047\n",
      " 0.16230366 0.11518325 0.06282723 0.0052356  0.15706806 0.17277487\n",
      " 0.15183246 0.08900524 0.04712042 0.21465969 0.33507853 0.18848168\n",
      " 0.10994764 0.05235602 0.45549738 0.05235602 0.02094241 0.04712042\n",
      " 0.29319372 0.03664921 0.0104712  0.39790576 0.08376963 0.01570681\n",
      " 0.14136126 0.17801047 0.19895288 0.12565445 0.34554974 0.62303665\n",
      " 0.13612565 0.         0.04188482 0.52879581 0.0104712  0.39790576\n",
      " 0.01570681 0.         0.18324607 0.06282723 0.28795812 0.13612565\n",
      " 0.05235602 0.01570681 0.35078534 0.21465969 0.43979058 0.39267016\n",
      " 0.43455497 0.28272251 0.13089005 0.27748691 0.33507853 0.58115183\n",
      " 0.53403141 0.05235602 0.21989529 0.35078534 0.05759162 0.21989529\n",
      " 0.02094241 0.2460733  0.68062827 0.61256545 0.65445026 0.0052356\n",
      " 0.         0.19895288 0.28795812 0.17277487 0.30366492 0.44502618\n",
      " 0.78010471 0.40314136 0.51832461 0.36649215 0.67539267 0.13612565\n",
      " 0.28795812 0.21989529 0.03664921 0.04712042 0.33507853 0.2565445\n",
      " 0.09424084 0.04188482 0.39790576 0.2460733  0.35078534 0.03664921\n",
      " 0.15706806 0.2513089  0.89005236 0.14136126 0.36125654 0.29842932\n",
      " 0.29319372 0.01570681 0.01570681 0.         0.14659686 0.0104712\n",
      " 0.03141361 0.         0.19371728 0.03664921 0.21989529 0.07853403\n",
      " 0.58638743 0.05759162 0.03664921 0.23036649 0.36125654 0.21465969\n",
      " 0.44502618 0.07853403 0.58115183 0.02617801 0.21465969 0.09424084\n",
      " 0.16230366 1.02094241 0.51832461 0.38743455]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# 打印划分后的数据集\n",
    "print(\"原始训练集特征 X_train:\")\n",
    "print(X_train)\n",
    "print(\"原始训练集标签 y_train:\")\n",
    "print(y_train)\n",
    "print(\"原始测试集特征 X_test:\")\n",
    "print(X_test)\n",
    "print(\"原始测试集标签 y_test:\")\n",
    "print(y_test)\n",
    "\n",
    "# 归一化特征数据\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 拟合训练集特征数据并进行归一化\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# 使用训练集的参数对测试集进行归一化\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 归一化标签数据（可选）\n",
    "y_scaler = MinMaxScaler()\n",
    "\n",
    "# 拟合训练集标签数据并进行归一化\n",
    "y_train_scaled = y_scaler.fit_transform(y_train.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 使用训练集的参数对测试集标签进行归一化\n",
    "y_test_scaled = y_scaler.transform(y_test.reshape(-1, 1)).flatten()\n",
    "\n",
    "# 打印归一化后的数据集\n",
    "print(\"\\n归一化后的训练集特征 X_train_scaled:\")\n",
    "print(X_train_scaled)\n",
    "print(\"\\n归一化后的训练集标签 y_train_scaled:\")\n",
    "print(y_train_scaled)\n",
    "print(\"\\n归一化后的测试集特征 X_test_scaled:\")\n",
    "print(X_test_scaled)\n",
    "print(\"\\n归一化后的测试集标签 y_test_scaled:\")\n",
    "print(y_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. 模型构建：请先构建一个**线性回归模型（多元一次函数）**，然后利用训练集训练模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 MSE: 994.784709028871\n",
      "训练集 R^2: 0.38196003909473375\n",
      "测试集 MSE: 996.5688433356044\n",
      "测试集 R^2: 0.3718395317360643\n",
      "模型系数: [[ 33.14686071  -0.55446073 -15.38569688  26.87019273  55.03201295\n",
      "    5.07876344]]\n",
      "模型截距: [-12.80682748]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "# 构建线性回归模型\n",
    "model = LinearRegression()\n",
    "\n",
    "# 使用训练集训练模型\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 预测训练集和测试集的结果\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# 计算模型的性能指标\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# 打印模型的性能指标\n",
    "print(\"训练集 MSE:\", train_mse)\n",
    "print(\"训练集 R^2:\", train_r2)\n",
    "print(\"测试集 MSE:\", test_mse)\n",
    "print(\"测试集 R^2:\", test_r2)\n",
    "\n",
    "# 打印模型的系数和截距\n",
    "print(\"模型系数:\", model.coef_)\n",
    "print(\"模型截距:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. 模型测试：利用测试集对训练好的模型进行评估。\n",
    "\n",
    "> 提示：使用`predict(data_array)`方法输入测试集，该函数返回值为模型预测值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算模型的性能指标\n",
    "train_mse = mean_squared_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "test_mse = mean_squared_error(y_test, y_test_pred)\n",
    "test_r2 = r2_score(y_test, y_test_pred)\n",
    "\n",
    "# 打印模型的性能指标\n",
    "print(\"训练集 MSE:\", train_mse)\n",
    "print(\"训练集 R^2:\", train_r2)\n",
    "print(\"测试集 MSE:\", test_mse)\n",
    "print(\"测试集 R^2:\", test_r2)\n",
    "\n",
    "# 打印模型的系数和截距\n",
    "print(\"模型系数:\", model.coef_)\n",
    "print(\"模型截距:\", model.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. 模型评估：请使用均方根误差（RMSE）作为评估指标，并输出RMSE值。\n",
    "\n",
    "均方根误差(Root of Mean Squared Error)，公式为\n",
    "$$\n",
    "RMSE=\\sqrt{\\frac{1}{n}\\sum_{i=1}^n(\\hat{y_i}-y_i)^2}\n",
    "$$\n",
    "可以直接通过对MSE求平方根获得。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集 RMSE: 31.540207815245463\n"
     ]
    }
   ],
   "source": [
    "train_rmse = np.sqrt(train_mse)\n",
    "print(\"训练集 RMSE:\", train_rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
